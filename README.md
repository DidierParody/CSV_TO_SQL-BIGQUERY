# ğŸŒ ETL de Datos ClimÃ¡ticos con BigQuery

## ğŸ“Œ DescripciÃ³n
Este proyecto implementa un pipeline **ETL (ExtracciÃ³n, TransformaciÃ³n y Carga)** que recopila datos climÃ¡ticos de varias ciudades, los procesa y los almacena en **Google BigQuery** para su posterior anÃ¡lisis.

El flujo de trabajo sigue tres fases principales:
1. **ExtracciÃ³n**: Obtiene datos climÃ¡ticos desde la API de Open-Meteo.
2. **TransformaciÃ³n**: Convierte y estructura los datos en un formato tabular.
3. **Carga**: Sube la informaciÃ³n procesada a una tabla en **BigQuery**.

## ğŸ› ï¸ TecnologÃ­as utilizadas
- **Python 3.12**
- **httpx** (para solicitudes HTTP asÃ­ncronas)
- **pandas** (para manipulaciÃ³n de datos)
- **Google BigQuery** (para almacenamiento y anÃ¡lisis de datos)
- **dotenv** (para gestiÃ³n de variables de entorno)

## ğŸ“‚ Estructura del proyecto
```
ETL_Project/
â”‚â”€â”€ extraction.py      # Extrae datos de Open-Meteo API
â”‚â”€â”€ transformation.py  # Procesa y estructura los datos
â”‚â”€â”€ load.py            # Sube los datos a BigQuery
â”‚â”€â”€ main.py            # Orquesta todo el flujo ETL
â”‚â”€â”€ .env               # Variables de entorno (no subir a GitHub)
â”‚â”€â”€ requirements.txt   # Dependencias del proyecto
â”‚â”€â”€ README.md          # DocumentaciÃ³n
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n
1. **Clonar el repositorio:**
   ```bash
   git clone https://github.com/tu_usuario/ETL_Project.git
   cd ETL_Project
   ```

2. **Crear un entorno virtual:**
   ```bash
   python3 -m venv etlenv
   source etlenv/bin/activate  # En Windows: etlenv\Scripts\activate
   ```

3. **Instalar dependencias:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configurar las variables de entorno:**
   Crea un archivo `.env` en la raÃ­z del proyecto y agrega:
   ```ini
   CREDENTIALS_PATH=/ruta/a/tu/credencial.json
   TABLE_ID=etl_proyecto.tu_tabla
   ```

## ğŸ—ï¸ Funcionamiento del ETL
### 1ï¸âƒ£ ExtracciÃ³n de Datos (`extraction.py`)
Este script obtiene datos climÃ¡ticos de **BogotÃ¡, MedellÃ­n, Barranquilla, Santa Marta y Bucaramanga** desde la API de Open-Meteo.

ğŸ“Œ *Ejemplo de datos extraÃ­dos:*
```json
{
  "bogota": {
    "hourly": {
      "temperature_2m": [15, 14, 13, 12],
      "relative_humidity_2m": [80, 82, 85, 90],
      "wind_speed_10m": [5, 6, 7, 8]
    }
  }
}
```

### 2ï¸âƒ£ TransformaciÃ³n de Datos (`transformation.py`)
Se convierte el JSON en un CSV estructurado y se normalizan los datos.

ğŸ“Œ *Ejemplo de datos transformados:*
```
ciudad, tiempo, temperatura_2m, humedad_relativa_2m, velocidad_viento_10m, categoria
BogotÃ¡, 2024-09-01T12:00, 15, 80, 5, temperature_2m
BogotÃ¡, 2024-09-01T13:00, 14, 82, 6, temperature_2m
```

### 3ï¸âƒ£ Carga de Datos a BigQuery (`load.py`)
Se envÃ­a el CSV final a **BigQuery**, detectando automÃ¡ticamente los tipos de datos.

ğŸ“Œ *CÃ³digo relevante:*
```python
job_config = bigquery.LoadJobConfig(
    source_format=bigquery.SourceFormat.CSV,
    autodetect=True,
    skip_leading_rows=1
)
job = client.load_table_from_dataframe(df, tabla_destino, job_config=job_config)
job.result()
```

## â–¶ï¸ EjecuciÃ³n del Pipeline
Para correr todo el flujo ETL, ejecuta:
```bash
python3 main.py
```
Esto ejecutarÃ¡ `extraction.py`, `transformation.py` y `load.py` en orden.

## ğŸ“Š Consulta de Datos en BigQuery
Para verificar que los datos llegaron correctamente a BigQuery, puedes ejecutar la siguiente consulta SQL:
```sql
SELECT * FROM `etl_proyecto.tu_tabla`
LIMIT 10;
```

## âœ¨ Contribuciones
Si deseas contribuir, haz un **fork** del proyecto, crea una rama, realiza tus cambios y envÃ­a un **pull request**.

## ğŸ“œ Licencia
Este proyecto estÃ¡ bajo la **Licencia MIT**.

---
ğŸ“Œ *Desarrollado por Didier JosÃ© Torres Parodis*


